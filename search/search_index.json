{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the GB-FS project, a comprehensive repository dedicated to advancing Graph-Based Feature Selection methodologies in machine learning. Our project houses two significant contributions to the field: GB-AFS and GB-BC-FS, each developed to address the intricate challenges of feature selection with graph-based solutions.</p>"},{"location":"#introduction","title":"Introduction","text":"<p>In the realm of machine learning and data science, efficiently handling and interpreting vast datasets is a pivotal challenge. The GB-FS project focuses on utilizing graph-based approaches for feature selection, aiming to improve model accuracy, reduce complexity, and enhance interpretability. By representing data as graphs, our methods discern the most relevant features by analyzing the structure and relationships within the dataset.</p>"},{"location":"#core-principles","title":"Core Principles","text":"<p>Our graph-based feature selection techniques rest on the foundation of identifying and leveraging the intricate connections between data points. This approach allows for a nuanced understanding of feature relevance and interdependencies, ensuring the selection of features that are crucial for the model's performance while eliminating redundant or irrelevant data. The GB-FS project is committed to pushing the boundaries of what's possible with feature selection, providing robust tools for researchers and developers alike.</p>"},{"location":"#our-contributions-gb-afs-and-gb-bc-fs","title":"Our Contributions: GB-AFS and GB-BC-FS","text":"<ul> <li> <p>GB-AFS (Graph-Based Automatic Feature Selection): A method that automates the process of feature selection for multi-class classification tasks, ensuring the minimal yet most effective set of features is utilized for model training.</p> </li> <li> <p>GB-BC-FS (Graph-Based Budget-Constrained Feature Selection): This method selects features for multi-class classification tasks while adhering to a budget limitation. It identifies the smallest necessary set of features to ensure that their total cost remains within the pre-set budget.</p> </li> </ul>"},{"location":"#explore-and-contribute","title":"Explore and Contribute","text":"<p>We invite you to explore our work, delve into the methodologies behind GB-AFS and GB-BC-FS, and contribute to the ongoing development and refinement of graph-based feature selection techniques. Your insights, feedback, and contributions are invaluable to advancing this field of study.</p> <ul> <li>Learn More About GB-AFS</li> <li>Learn More About GB-BC-FS</li> </ul>"},{"location":"gb_afs/","title":"GB-AFS","text":"<p>GB-AFS (Graph-Based Automatic Feature Selection) is an approach designed to identify the optimal subset of features necessary for maintaining predictive performance, without necessitating user-specified parameters, such as the desired number of features to include. This self-sufficiency is what attributes the 'Automatic' aspect to its name. Operating as a filter-based methodology, GB-AFS is model-agnostic, allowing for the integration of feature selection seamlessly into the preprocessing phase, regardless of the predictive model being used.</p> <p>The primary innovation and strength of GB-AFS lie in its unique capability to autonomously determine the smallest set of features required, circumventing the common limitation among filter-based methods that typically rely on user input for configuration.</p>"},{"location":"gb_afs/#using-gb-afs-code-examples-and-visualization","title":"Using GB-AFS: Code Examples and Visualization","text":"<p>GBFS offers a versatile and user-friendly Python library for feature selection in multi-class classification tasks. This section guides you through initializing the GB-AFS object with your dataset, selecting features, and visualizing the feature space.</p>"},{"location":"gb_afs/#initialization-and-parameters","title":"Initialization and Parameters","text":"<p>To start using GB-AFS, you first need to initialize the GB-AFS object with your dataset and selection criteria:</p> main.py<pre><code>from gbfs import GBAFS\n\ngbafs = GBAFS(\n    dataset_path=\"path/to/your/dataset.csv\",\n    separability_metric=\"your_separability_metric\",\n    dim_reducer_model=\"your_dimensionality_reduction_method\",\n    label_column=\"class\",\n)\n</code></pre>"},{"location":"gb_afs/#parameters-explained","title":"Parameters Explained","text":"<ul> <li><code>dataset_path</code>: Path to your dataset file. Ensure your dataset is in a CSV format or another compatible format.</li> <li><code>separability_metric</code>: Metric for evaluating feature separability. </li> <li><code>dim_reducer_model</code>: Dimensionality reduction model applying to your dataset. Must implement a <code>fit_transform</code> method for compatibility.</li> <li><code>label_column</code>: Name of the column with labels in your dataset. Defaults to <code>'class'</code>.</li> </ul> <p>Current supported metrics for <code>separability_metric</code> are <code>jm</code>, <code>bhattacharyya</code>, and <code>wasserstein</code>. To request support for additional metrics, please open an issue in the repository.</p>"},{"location":"gb_afs/#feature-selection","title":"Feature Selection","text":"<p>Once the GB-AFS object is initialized, you can proceed with the feature selection process:</p> <p>main.py<pre><code>selected_features = gbafs.select_features()\n\nprint(\"Selected Feature Indices:\", selected_features)\n</code></pre> This method returns a list of indices for the features deemed most relevant by the GB-AFS algorithm.</p>"},{"location":"gb_afs/#visualizing-the-feature-space","title":"Visualizing the Feature Space","text":"<p>GB-AFS also includes a method to visualize the selected features within the feature space, providing insights into their distribution and separability:</p> main.py<pre><code>gbafs.plot_feature_space()\n</code></pre> <p>This method generates a scatter plot highlighting the selected features. Features are displayed with their separability power indicated by color intensity, and selected features are marked distinctly.</p>"},{"location":"gb_afs/#references-and-further-reading","title":"References and Further Reading","text":"<p>For a deeper understanding of the GB-AFS method and its background, consider exploring the official paper.</p>"},{"location":"gb_bc_fs/","title":"GB-BC-FS","text":"<p>GB-BC-FS (Graph-Based Budget-Constraint Feature Selection) is an approach designed to efficiently handle large datasets with numerous features under budget constraints. Unlike traditional methods that generate multiple candidate solutions, GB-BC-FS starts with a single solution and refines it to meet budgetary limits, significantly reducing computational time. The process utilizes the GB-AFS method, which selects a minimal set of features necessary for accuracy in multi-class classification by assessing the discriminative power of features across class pairs.</p> <p>To ensure feature diversity and accommodate budget constraints, the method includes a heuristic refinement step that adjusts the initial feature set. This adjustment is based on a scoring function that favors lower-cost features, simplifying the feature selection process and enhancing robustness. The approach also evaluates the interrelationships among features, moving beyond traditional isolated assessments.</p>"},{"location":"gb_bc_fs/#using-gb-bc-fs-code-examples-and-visualization","title":"Using GB-BC-FS: Code Examples and Visualization","text":"<p>GBFS offers a versatile and user-friendly Python library for feature selection in multi-class classification tasks. This section guides you through initializing the GB-BC-FS object with your dataset, selecting features, and visualizing the feature space.</p>"},{"location":"gb_bc_fs/#initialization-and-parameters","title":"Initialization and Parameters","text":"<p>To start using GB-AFS, you first need to initialize the GB-AFS object with your dataset and selection criteria:</p> main.py<pre><code>from gbfs import GBBCFS\n\ngbbcfs = GBBCFS(\n    dataset_path=\"path/to/your/dataset.csv\",\n    separability_metric=\"your_separability_metric\",\n    dim_reducer_model=\"your_dimensionality_reduction_method\",\n    label_column=\"class\",\n    budget=20,\n    alpha=0.5,\n    epochs=100,\n)\n</code></pre>"},{"location":"gb_bc_fs/#parameters-explained","title":"Parameters Explained","text":"<ul> <li><code>dataset_path</code>: Path to your dataset file. Ensure your dataset is in a CSV format or another compatible format.</li> <li><code>separability_metric</code>: Metric for evaluating feature separability. </li> <li><code>dim_reducer_model</code>: Dimensionality reduction model applying to your dataset. Must implement a <code>fit_transform</code> method for compatibility.</li> <li><code>budget</code>: Numeric limit for the total allowable cost of selected features.</li> <li><code>label_column</code>: Name of the column with labels in your dataset. Defaults to <code>'class'</code>.</li> <li><code>alpha</code>: A parameter defines the cost function's scoring method related to the heuristic. Defaults to <code>0.5</code>. See the paper for further details.</li> <li><code>epochs</code>: The number of iterations the heuristic uses to solve for each potential k value. Defaults to <code>100</code>. See the paper for further details.</li> </ul> <p>Current supported metrics for <code>separability_metric</code> are <code>jm</code>, <code>bhattacharyya</code>, and <code>wasserstein</code>. To request support for additional metrics, please open an issue in the repository.</p> <p>NOTE: This method requires that the cost associated with each feature be specified in the dataset file, specifically on the second line. Please verify this arrangement to ensure proper functionality.</p>"},{"location":"gb_bc_fs/#feature-selection","title":"Feature Selection","text":"<p>Once the GB-BC-FS object is initialized, you can proceed with the feature selection process:</p> <p>main.py<pre><code>selected_features = gbbcfs.select_features()\n\nprint(\"Selected Feature Indices:\", selected_features)\n</code></pre> This method returns the list of features found by the GB-BC-FS algorithm, such that it meets the budget constraints.</p>"},{"location":"gb_bc_fs/#visualizing-the-feature-space","title":"Visualizing the Feature Space","text":"<p>GB-BC-FS includes a visualization method for presenting selected features within the feature space, offering insights into their distribution and separation. This visualization features two adjacent graphs: the left graph depicts the initial outcomes of the GB-AFS method, while the right graph shows the final results of the GB-BC-FS algorithm after heuristic adjustments have been applied.</p> <p>The feature spaces displayed in both graphs will be similar, yet there may be notable differences in how the features are clustered and selected. This assumes that the initial solution provided by the GB-AFS algorithm was deemed inadequate, prompting the activation of heuristics. main.py<pre><code>gbbcfs.plot_feature_space()\n</code></pre></p> <p>This method generates a scatter plot highlighting the selected features. Features are displayed with their separability power indicated by color intensity, and selected features are marked distinctly.</p>"},{"location":"gb_bc_fs/#get-the-selected-features","title":"Get the Selected Features","text":"<p>You can get the selected features in a dictionary format using the following command: main.py<pre><code>print(gbbcfs.selected_features_to_cost)\n</code></pre></p>"},{"location":"gb_bc_fs/#references-and-further-reading","title":"References and Further Reading","text":"<p>For a deeper understanding of the GB-AFS method and its background, consider exploring the official paper.</p>"}]}